import {errMsg, logger} from "./Logger.js";
import {config} from '../config.js';
import path from 'path';
import {checkOllamaHealth} from '../OllamaClient.js';
import {checkAnthropicHealth} from '../AnthropicClient.js';
import {connectMQTT} from '../mqttClient.js';
import {ElevenLabsTTS} from "./ElevenLabsTTS.js";
<<<<<<< HEAD
import {synthesizeSpeech as piperSynthesize} from '../piperTTS.js';
import {checkAlsaDevice} from "../audio/AudioUtils.js";
import {AudioPlayer} from "../audio/AudioPlayer.js";
import {safeDetectorReset} from "./XStateHelpers.js";
=======
import {checkAlsaDevice} from "../audio/AudioUtils.js";
import {AudioPlayer} from "../audio/AudioPlayer.js";
import {safeDetectorReset} from "./XStateHelpers.js";
<<<<<<< HEAD
import {getDevicesForAI} from "zwave-mcp-server/client";
import {initializeMCPClient} from "../mcpZWaveClient.js";
>>>>>>> f5a9006 (refactor: standardize file naming to PascalCase/camelCase)
=======
>>>>>>> e4aafe6 (feat: skip transcription when no speech detected)
import {OpenWakeWordDetector} from "./OpenWakeWordDetector.js";

// Platform helpers
const isLinux = process.platform === 'linux';


async function initServices() {
    logger.info('üöÄ Voice Gateway (OpenWakeWord) starting...');
    logger.debug(`Audio config: micDevice=${config.audio.micDevice}, sampleRate=${config.audio.sampleRate}, channels=${config.audio.channels}`);

    await initMQTT();
    await checkAIHealth();
    await checkTTSHealth();
    if (isLinux) await checkAlsa();
<<<<<<< HEAD
<<<<<<< HEAD
    // Note: Z-Wave MCP initialization is now handled in main.js with tool registry
=======
    await initZWave();
>>>>>>> f5a9006 (refactor: standardize file naming to PascalCase/camelCase)
=======
    // Note: Z-Wave MCP initialization is now handled in main.js with tool registry
>>>>>>> e4aafe6 (feat: skip transcription when no speech detected)
}

async function initMQTT() {
    try {
        await connectMQTT();
        logger.debug('‚úÖ MQTT connection established');
    } catch (err) {
        logger.error('‚ùå Failed to connect to MQTT broker', {error: errMsg(err)});
        logger.warn('‚ö†Ô∏è Continuing without MQTT - AI responses will be logged only');
    }
}

async function checkAIHealth() {
    if (config.ai.provider === 'anthropic') {
        logger.info('ü§ñ Using Anthropic (Claude) for AI inference');
        try {
            const ready = await checkAnthropicHealth();
            if (!ready) logger.warn('‚ö†Ô∏è Anthropic not ready - AI responses may fail');
        } catch (err) {
            logger.error('‚ùå Anthropic health check failed', {error: errMsg(err)});
        }
    } else {
        logger.info('ü§ñ Using Ollama for AI inference');
        try {
            const ready = await checkOllamaHealth();
            if (!ready) logger.warn('‚ö†Ô∏è Ollama not ready - AI responses may fail');
        } catch (err) {
            logger.error('‚ùå Ollama health check failed', {error: errMsg(err)});
        }
    }
}

async function checkTTSHealth() {
    if (!config.tts.enabled) return;
    try {
        const tts = new ElevenLabsTTS(config, logger);
        const ready = await tts.checkHealth();
        if (!ready) {
            logger.warn('‚ö†Ô∏è ElevenLabs TTS not ready - AI responses will not be spoken');
        }
    } catch (err) {
        logger.error('‚ùå ElevenLabs TTS health check failed', {error: errMsg(err)});
    }
}

async function checkAlsa() {
    try {
        await checkAlsaDevice(config.audio.micDevice, config.audio.sampleRate, config.audio.channels);
    } catch (err) {
        logger.error('‚ùå ALSA device check failed', {device: config.audio.micDevice, error: errMsg(err)});
    }
}

<<<<<<< HEAD
<<<<<<< HEAD
async function setupWakeWordDetector(wakeWordMachine = null) {
    const modelsDir = path.dirname(config.openWakeWord.modelPath);
    const modelFile = path.basename(config.openWakeWord.modelPath);
    const detector = new OpenWakeWordDetector(
        modelsDir,
        modelFile,
        config.openWakeWord.threshold,
        config.openWakeWord.embeddingFrames,
        config.openWakeWord.warmupMs
    );
    await detector.initialize();

    // Connect detector to WakeWordMachine if provided
    if (wakeWordMachine) {
        // Notify machine that detector is initialized
        wakeWordMachine.send({ type: 'DETECTOR_INITIALIZED', detector });

        // Listen for warmup-complete event and notify machine
        detector.on('warmup-complete', () => {
            logger.debug('[InitUtil] Detector warmup-complete event received, notifying WakeWordMachine');
            wakeWordMachine.send({ type: 'WARMUP_COMPLETE' });
        });

        logger.debug('[InitUtil] Detector connected to WakeWordMachine');
    }

    // Warm-up will happen automatically in background once mic starts feeding audio
    logger.info('‚úÖ Detector initialized (warm-up will occur automatically)');

    return detector;
}

/**
 * Pre-synthesize welcome message audio (non-blocking)
 * This allows synthesis to happen in parallel with other initialization tasks
 *
 * @returns {Promise<Float32Array|null>} Pre-synthesized audio buffer or null on failure
 */
async function synthesizeWelcomeMessage() {
    if (!config.tts.enabled) return null;

    try {
        const provider = config.tts.provider || 'ElevenLabs';
        logger.debug('üîß [STARTUP-DEBUG] synthesizeWelcomeMessage: Starting TTS synthesis in background...', {provider});

        const welcomeMessage = 'Hello, I am Jarvis. How can I help?';
        let audioBuffer;

        if (provider === 'Piper') {
            // Use Piper TTS (local/offline)
            audioBuffer = await piperSynthesize(welcomeMessage, {
                volume: config.tts.volume,
                speed: config.tts.speed
            });
        } else {
            // Use ElevenLabs TTS (cloud)
            const tts = new ElevenLabsTTS(config, logger);
            audioBuffer = await tts.synthesizeSpeech(welcomeMessage, {
                volume: config.tts.volume,
                speed: config.tts.speed
            });
        }

        logger.debug('üîß [STARTUP-DEBUG] synthesizeWelcomeMessage: TTS synthesis complete');
        return audioBuffer;
    } catch (err) {
        logger.error('‚ùå Failed to synthesize welcome message', {error: err.message});
        return null;
    }
}

/**
 * Play pre-synthesized welcome message
 * @param {Float32Array|null} audioBuffer - Pre-synthesized audio buffer
 * @param {Object} detector - Wake word detector instance (unused, kept for backwards compatibility)
 * @param {Object} audioPlayer - Audio player instance
 * @param {Object} beeps - Beep sounds object
 * @returns {Object|null} Playback handle for interruption support
 */
async function startTTSWelcome(audioBuffer, detector, audioPlayer, beeps = null) {
    if (!audioBuffer || !config.tts.enabled) {
        logger.debug('üîß [STARTUP-DEBUG] startTTSWelcome: No audio buffer or TTS disabled, skipping welcome');
        return null;
    }
=======
async function initZWave() {
    try {
        logger.info('üîå Initializing ZWave MCP client...');
        await initializeMCPClient();
        const deviceInfo = await getDevicesForAI();
        logger.info('‚úÖ Z-Wave connection successful!');
        logger.debug('üìã Devices:', deviceInfo);
    } catch (err) {
        logger.error('‚ùå ZWave MCP client initialization failed', {error: errMsg(err)});
    }
}

=======
>>>>>>> e4aafe6 (feat: skip transcription when no speech detected)
async function setupWakeWordDetector() {
    const modelsDir = path.dirname(config.openWakeWord.modelPath);
    const modelFile = path.basename(config.openWakeWord.modelPath);
    const detector = new OpenWakeWordDetector(modelsDir, modelFile, config.openWakeWord.threshold, config.openWakeWord.embeddingFrames);
    await detector.initialize();

    // Warm-up will happen automatically in background once mic starts feeding audio
    logger.info('‚úÖ Detector initialized (warm-up will occur automatically)');

    return detector;
}

async function startTTSWelcome(detector, audioPlayer) {
    if (!config.tts.enabled) return;
>>>>>>> f5a9006 (refactor: standardize file naming to PascalCase/camelCase)

    // Create AudioPlayer if not provided (for backward compatibility)
    const player = audioPlayer || new AudioPlayer(config, logger);

    try {
<<<<<<< HEAD
        logger.debug('üîß [STARTUP-DEBUG] startTTSWelcome: Starting playback of pre-synthesized audio...');

        if (audioBuffer.length > 0) {
            // Use playInterruptible for cancellable welcome message
            const playback = player.playInterruptible(audioBuffer);

            // Play in background, handle completion/cancellation
            playback.promise
                .then(() => {
                    logger.debug('üîß [STARTUP-DEBUG] startTTSWelcome: Playback completed');
                    logger.info('‚úÖ Welcome message spoken');
                    // REMOVED: Post-welcome detector reset (no longer needed with warm-up wait)
                    // The detector is already warmed up before welcome message plays
                    // Beep isolation prevents TTS audio from being recorded

                    // Play ready-to-listen beep to signal system is ready for wake word
                    if (beeps && beeps.ready) {
                        logger.debug('üîî Playing ready-to-listen beep');
                        player.play(beeps.ready)
                            .then(() => {
                                logger.debug('‚úÖ Ready beep played');
                            })
                            .catch(err => {
                                logger.warn('‚ö†Ô∏è Failed to play ready beep', { error: err.message });
                                // Non-critical failure - continue
                            });
                    }
                })
                .catch(err => {
                    if (err.message.includes('cancelled')) {
                        logger.info('üõë Welcome message interrupted');
                    } else {
                        logger.error('‚ùå Failed to play welcome message', {error: err.message});
                    }
                });

            // Return playback handle for interruption support
            return playback;
        }
    } catch (err) {
        logger.error('‚ùå Failed to play welcome message', {error: err.message});
    }

    return null;
=======
        const tts = new ElevenLabsTTS(config, logger);
        const welcomeMessage = 'Hello, I am Jarvis. How can I help?';
        const audioBuffer = await tts.synthesizeSpeech(welcomeMessage, {
            volume: config.tts.volume,
            speed: config.tts.speed
        });
        if (audioBuffer && audioBuffer.length > 0) {
            await player.play(audioBuffer);
            logger.info('‚úÖ Welcome message spoken');
            await new Promise(resolve => setTimeout(resolve, 1000));
            safeDetectorReset(detector, 'post-startup-tts');
        }
    } catch (err) {
        logger.error('‚ùå Failed to speak welcome message', {error: err.message});
    }
>>>>>>> f5a9006 (refactor: standardize file naming to PascalCase/camelCase)
}

export {
    initServices,
    setupWakeWordDetector,
<<<<<<< HEAD
    synthesizeWelcomeMessage,
=======
>>>>>>> f5a9006 (refactor: standardize file naming to PascalCase/camelCase)
    startTTSWelcome,
    checkAIHealth,
    checkAlsa,
    checkTTSHealth
}
